{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, label = 32\r\n",
      "Batch 0, loss = 0.010047\r\n",
      "Batch 0, loss = 0.00961618\r\n",
      "Batch 0, loss = 0.0102093\r\n",
      "Batch 0, loss = 0.0100273\r\n",
      "Batch 0, loss = 0.00961008\r\n",
      "Batch 0, loss = 0.0103932\r\n",
      "Batch 0, loss = 0.0101413\r\n",
      "Batch 0, loss = 0.00993649\r\n",
      "Batch 0, loss = 0.0101155\r\n",
      "Batch 0, loss = 0.0103679\r\n",
      "Batch 0, loss = 0.0101035\r\n",
      "Batch 0, loss = 0.0100854\r\n",
      "Batch 0, loss = 0.00983509\r\n",
      "Batch 0, loss = 0.00963998\r\n",
      "Batch 0, loss = 0.00958064\r\n",
      "Batch 0, loss = 0.0105444\r\n",
      "Batch 0, loss = 0.0104419\r\n",
      "Batch 0, loss = 0.0099154\r\n",
      "Batch 0, loss = 0.0092118\r\n",
      "Batch 0, loss = 0.0097413\r\n",
      "Batch 0, loss = 0.00971739\r\n",
      "Batch 0, loss = 0.00974267\r\n",
      "Batch 0, loss = 0.0102133\r\n",
      "Batch 0, loss = 0.010542\r\n",
      "Batch 0, loss = 0.00953141\r\n",
      "Batch 0, loss = 0.0104378\r\n",
      "Batch 0, loss = 0.0107075\r\n",
      "Batch 0, loss = 0.00941875\r\n",
      "Batch 0, loss = 0.00978815\r\n",
      "Batch 0, loss = 0.00974486\r\n",
      "Batch 0, loss = 0.00985153\r\n",
      "Batch 0, loss = 0.00998786\r\n",
      "Batch 0, loss = 0.00998568\r\n",
      "Batch 0, loss = 0.00994011\r\n",
      "Batch 0, loss = 0.00997482\r\n",
      "Batch 0, loss = 0.0102614\r\n",
      "Batch 0, loss = 0.00970271\r\n",
      "Batch 0, loss = 0.00941912\r\n",
      "Batch 0, loss = 0.0104025\r\n",
      "Batch 0, loss = 0.00983478\r\n",
      "Batch 0, loss = 0.00967896\r\n",
      "Batch 0, loss = 0.0106589\r\n",
      "Batch 0, loss = 0.00977467\r\n",
      "Batch 0, loss = 0.0105188\r\n",
      "Batch 0, loss = 0.00978854\r\n",
      "Batch 0, loss = 0.00958116\r\n",
      "Batch 0, loss = 0.00990993\r\n",
      "Batch 0, loss = 0.00996057\r\n",
      "Batch 0, loss = 0.00999409\r\n",
      "Batch 0, loss = 0.00957556\r\n",
      "Batch 0, loss = 0.0097228\r\n",
      "Batch 0, loss = 0.00989254\r\n",
      "Batch 0, loss = 0.00959422\r\n",
      "Batch 0, loss = 0.0100274\r\n",
      "Batch 0, loss = 0.00942379\r\n",
      "Batch 0, loss = 0.0101495\r\n",
      "Batch 0, loss = 0.00935208\r\n",
      "Batch 0, loss = 0.00959651\r\n",
      "Batch 0, loss = 0.0106419\r\n",
      "Batch 0, loss = 0.0103855\r\n",
      "Batch 0, loss = 0.0104327\r\n",
      "Batch 0, loss = 0.0105444\r\n",
      "Batch 0, loss = 0.010545\r\n",
      "Batch 0, loss = 0.00918817\r\n",
      "Batch 0, loss = 0.0102999\r\n",
      "Batch 0, loss = 0.00955119\r\n",
      "Batch 0, loss = 0.0093046\r\n",
      "Batch 0, loss = 0.010172\r\n",
      "Batch 0, loss = 0.00935569\r\n",
      "Batch 0, loss = 0.00913978\r\n",
      "Batch 0, loss = 0.0102677\r\n",
      "Batch 0, loss = 0.00919225\r\n",
      "Batch 0, loss = 0.0093193\r\n",
      "Batch 0, loss = 0.0100226\r\n",
      "Batch 0, loss = 0.00941641\r\n",
      "Batch 0, loss = 0.00993558\r\n",
      "Batch 0, loss = 0.00977336\r\n",
      "Batch 0, loss = 0.0105238\r\n",
      "Batch 0, loss = 0.0103626\r\n",
      "Batch 0, loss = 0.00954763\r\n",
      "Batch 0, loss = 0.00982931\r\n",
      "Batch 0, loss = 0.00923184\r\n",
      "Batch 0, loss = 0.00968352\r\n",
      "Batch 0, loss = 0.0101713\r\n",
      "Batch 0, loss = 0.010058\r\n",
      "Batch 0, loss = 0.00929719\r\n",
      "Batch 0, loss = 0.00950997\r\n",
      "Batch 0, loss = 0.00986729\r\n",
      "Batch 0, loss = 0.00997283\r\n",
      "Batch 0, loss = 0.0100032\r\n",
      "Batch 0, loss = 0.00926699\r\n",
      "Batch 0, loss = 0.0106061\r\n",
      "Batch 0, loss = 0.00980864\r\n",
      "Batch 0, loss = 0.00991424\r\n",
      "Batch 0, loss = 0.00998448\r\n",
      "Batch 0, loss = 0.00931214\r\n",
      "Batch 0, loss = 0.00945166\r\n",
      "Batch 0, loss = 0.00968032\r\n",
      "Batch 0, loss = 0.0101471\r\n",
      "Batch 0, loss = 0.0103083\r\n",
      "Batch 0, loss = 0.0100056\r\n",
      "Batch 1, label = 27\r\n",
      "Batch 1, loss = 0.010047\r\n",
      "Batch 1, loss = 0.00961618\r\n",
      "Batch 1, loss = 0.0102093\r\n",
      "Batch 1, loss = 0.0100273\r\n",
      "Batch 1, loss = 0.00961008\r\n",
      "Batch 1, loss = 0.0103932\r\n",
      "Batch 1, loss = 0.0101413\r\n",
      "Batch 1, loss = 0.00993649\r\n",
      "Batch 1, loss = 0.0101155\r\n",
      "Batch 1, loss = 0.0103679\r\n",
      "Batch 1, loss = 0.0101035\r\n",
      "Batch 1, loss = 0.0100854\r\n",
      "Batch 1, loss = 0.00983509\r\n",
      "Batch 1, loss = 0.00963998\r\n",
      "Batch 1, loss = 0.00958064\r\n",
      "Batch 1, loss = 0.0105444\r\n",
      "Batch 1, loss = 0.0104419\r\n",
      "Batch 1, loss = 0.0099154\r\n",
      "Batch 1, loss = 0.0092118\r\n",
      "Batch 1, loss = 0.0097413\r\n",
      "Batch 1, loss = 0.00971739\r\n",
      "Batch 1, loss = 0.00974267\r\n",
      "Batch 1, loss = 0.0102133\r\n",
      "Batch 1, loss = 0.010542\r\n",
      "Batch 1, loss = 0.00953141\r\n",
      "Batch 1, loss = 0.0104378\r\n",
      "Batch 1, loss = 0.0107075\r\n",
      "Batch 1, loss = 0.00941875\r\n",
      "Batch 1, loss = 0.00978815\r\n",
      "Batch 1, loss = 0.00974486\r\n",
      "Batch 1, loss = 0.00985153\r\n",
      "Batch 1, loss = 0.00998786\r\n",
      "Batch 1, loss = 0.00998568\r\n",
      "Batch 1, loss = 0.00994011\r\n",
      "Batch 1, loss = 0.00997482\r\n",
      "Batch 1, loss = 0.0102614\r\n",
      "Batch 1, loss = 0.00970271\r\n",
      "Batch 1, loss = 0.00941912\r\n",
      "Batch 1, loss = 0.0104025\r\n",
      "Batch 1, loss = 0.00983478\r\n",
      "Batch 1, loss = 0.00967896\r\n",
      "Batch 1, loss = 0.0106589\r\n",
      "Batch 1, loss = 0.00977467\r\n",
      "Batch 1, loss = 0.0105188\r\n",
      "Batch 1, loss = 0.00978854\r\n",
      "Batch 1, loss = 0.00958116\r\n",
      "Batch 1, loss = 0.00990993\r\n",
      "Batch 1, loss = 0.00996057\r\n",
      "Batch 1, loss = 0.00999409\r\n",
      "Batch 1, loss = 0.00957556\r\n",
      "Batch 1, loss = 0.0097228\r\n",
      "Batch 1, loss = 0.00989254\r\n",
      "Batch 1, loss = 0.00959422\r\n",
      "Batch 1, loss = 0.0100274\r\n",
      "Batch 1, loss = 0.00942379\r\n",
      "Batch 1, loss = 0.0101495\r\n",
      "Batch 1, loss = 0.00935208\r\n",
      "Batch 1, loss = 0.00959651\r\n",
      "Batch 1, loss = 0.0106419\r\n",
      "Batch 1, loss = 0.0103855\r\n",
      "Batch 1, loss = 0.0104327\r\n",
      "Batch 1, loss = 0.0105444\r\n",
      "Batch 1, loss = 0.010545\r\n",
      "Batch 1, loss = 0.00918817\r\n",
      "Batch 1, loss = 0.0102999\r\n",
      "Batch 1, loss = 0.00955119\r\n",
      "Batch 1, loss = 0.0093046\r\n",
      "Batch 1, loss = 0.010172\r\n",
      "Batch 1, loss = 0.00935569\r\n",
      "Batch 1, loss = 0.00913978\r\n",
      "Batch 1, loss = 0.0102677\r\n",
      "Batch 1, loss = 0.00919225\r\n",
      "Batch 1, loss = 0.0093193\r\n",
      "Batch 1, loss = 0.0100226\r\n",
      "Batch 1, loss = 0.00941641\r\n",
      "Batch 1, loss = 0.00993558\r\n",
      "Batch 1, loss = 0.00977336\r\n",
      "Batch 1, loss = 0.0105238\r\n",
      "Batch 1, loss = 0.0103626\r\n",
      "Batch 1, loss = 0.00954763\r\n",
      "Batch 1, loss = 0.00982931\r\n",
      "Batch 1, loss = 0.00923184\r\n",
      "Batch 1, loss = 0.00968352\r\n",
      "Batch 1, loss = 0.0101713\r\n",
      "Batch 1, loss = 0.010058\r\n",
      "Batch 1, loss = 0.00929719\r\n",
      "Batch 1, loss = 0.00950997\r\n",
      "Batch 1, loss = 0.00986729\r\n",
      "Batch 1, loss = 0.00997283\r\n",
      "Batch 1, loss = 0.0100032\r\n",
      "Batch 1, loss = 0.00926699\r\n",
      "Batch 1, loss = 0.0106061\r\n",
      "Batch 1, loss = 0.00980864\r\n",
      "Batch 1, loss = 0.00991424\r\n",
      "Batch 1, loss = 0.00998448\r\n",
      "Batch 1, loss = 0.00931214\r\n",
      "Batch 1, loss = 0.00945166\r\n",
      "Batch 1, loss = 0.00968032\r\n",
      "Batch 1, loss = 0.0101471\r\n",
      "Batch 1, loss = 0.0103083\r\n",
      "Batch 1, loss = 0.0100056\r\n",
      "Batch 2, label = 65\r\n",
      "Batch 2, loss = 0.010047\r\n",
      "Batch 2, loss = 0.00961618\r\n",
      "Batch 2, loss = 0.0102093\r\n",
      "Batch 2, loss = 0.0100273\r\n",
      "Batch 2, loss = 0.00961008\r\n",
      "Batch 2, loss = 0.0103932\r\n",
      "Batch 2, loss = 0.0101413\r\n",
      "Batch 2, loss = 0.00993649\r\n",
      "Batch 2, loss = 0.0101155\r\n",
      "Batch 2, loss = 0.0103679\r\n",
      "Batch 2, loss = 0.0101035\r\n",
      "Batch 2, loss = 0.0100854\r\n",
      "Batch 2, loss = 0.00983509\r\n",
      "Batch 2, loss = 0.00963998\r\n",
      "Batch 2, loss = 0.00958064\r\n",
      "Batch 2, loss = 0.0105444\r\n",
      "Batch 2, loss = 0.0104419\r\n",
      "Batch 2, loss = 0.0099154\r\n",
      "Batch 2, loss = 0.0092118\r\n",
      "Batch 2, loss = 0.0097413\r\n",
      "Batch 2, loss = 0.00971739\r\n",
      "Batch 2, loss = 0.00974267\r\n",
      "Batch 2, loss = 0.0102133\r\n",
      "Batch 2, loss = 0.010542\r\n",
      "Batch 2, loss = 0.00953141\r\n",
      "Batch 2, loss = 0.0104378\r\n",
      "Batch 2, loss = 0.0107075\r\n",
      "Batch 2, loss = 0.00941875\r\n",
      "Batch 2, loss = 0.00978815\r\n",
      "Batch 2, loss = 0.00974486\r\n",
      "Batch 2, loss = 0.00985153\r\n",
      "Batch 2, loss = 0.00998786\r\n",
      "Batch 2, loss = 0.00998568\r\n",
      "Batch 2, loss = 0.00994011\r\n",
      "Batch 2, loss = 0.00997482\r\n",
      "Batch 2, loss = 0.0102614\r\n",
      "Batch 2, loss = 0.00970271\r\n",
      "Batch 2, loss = 0.00941912\r\n",
      "Batch 2, loss = 0.0104025\r\n",
      "Batch 2, loss = 0.00983478\r\n",
      "Batch 2, loss = 0.00967896\r\n",
      "Batch 2, loss = 0.0106589\r\n",
      "Batch 2, loss = 0.00977467\r\n",
      "Batch 2, loss = 0.0105188\r\n",
      "Batch 2, loss = 0.00978854\r\n",
      "Batch 2, loss = 0.00958116\r\n",
      "Batch 2, loss = 0.00990993\r\n",
      "Batch 2, loss = 0.00996057\r\n",
      "Batch 2, loss = 0.00999409\r\n",
      "Batch 2, loss = 0.00957556\r\n",
      "Batch 2, loss = 0.0097228\r\n",
      "Batch 2, loss = 0.00989254\r\n",
      "Batch 2, loss = 0.00959422\r\n",
      "Batch 2, loss = 0.0100274\r\n",
      "Batch 2, loss = 0.00942379\r\n",
      "Batch 2, loss = 0.0101495\r\n",
      "Batch 2, loss = 0.00935208\r\n",
      "Batch 2, loss = 0.00959651\r\n",
      "Batch 2, loss = 0.0106419\r\n",
      "Batch 2, loss = 0.0103855\r\n",
      "Batch 2, loss = 0.0104327\r\n",
      "Batch 2, loss = 0.0105444\r\n",
      "Batch 2, loss = 0.010545\r\n",
      "Batch 2, loss = 0.00918817\r\n",
      "Batch 2, loss = 0.0102999\r\n",
      "Batch 2, loss = 0.00955119\r\n",
      "Batch 2, loss = 0.0093046\r\n",
      "Batch 2, loss = 0.010172\r\n",
      "Batch 2, loss = 0.00935569\r\n",
      "Batch 2, loss = 0.00913978\r\n",
      "Batch 2, loss = 0.0102677\r\n",
      "Batch 2, loss = 0.00919225\r\n",
      "Batch 2, loss = 0.0093193\r\n",
      "Batch 2, loss = 0.0100226\r\n",
      "Batch 2, loss = 0.00941641\r\n",
      "Batch 2, loss = 0.00993558\r\n",
      "Batch 2, loss = 0.00977336\r\n",
      "Batch 2, loss = 0.0105238\r\n",
      "Batch 2, loss = 0.0103626\r\n",
      "Batch 2, loss = 0.00954763\r\n",
      "Batch 2, loss = 0.00982931\r\n",
      "Batch 2, loss = 0.00923184\r\n",
      "Batch 2, loss = 0.00968352\r\n",
      "Batch 2, loss = 0.0101713\r\n",
      "Batch 2, loss = 0.010058\r\n",
      "Batch 2, loss = 0.00929719\r\n",
      "Batch 2, loss = 0.00950997\r\n",
      "Batch 2, loss = 0.00986729\r\n",
      "Batch 2, loss = 0.00997283\r\n",
      "Batch 2, loss = 0.0100032\r\n",
      "Batch 2, loss = 0.00926699\r\n",
      "Batch 2, loss = 0.0106061\r\n",
      "Batch 2, loss = 0.00980864\r\n",
      "Batch 2, loss = 0.00991424\r\n",
      "Batch 2, loss = 0.00998448\r\n",
      "Batch 2, loss = 0.00931214\r\n",
      "Batch 2, loss = 0.00945166\r\n",
      "Batch 2, loss = 0.00968032\r\n",
      "Batch 2, loss = 0.0101471\r\n",
      "Batch 2, loss = 0.0103083\r\n",
      "Batch 2, loss = 0.0100056\r\n",
      "Batch 3, label = 56\r\n",
      "Batch 3, loss = 0.010047\r\n",
      "Batch 3, loss = 0.00961618\r\n",
      "Batch 3, loss = 0.0102093\r\n",
      "Batch 3, loss = 0.0100273\r\n",
      "Batch 3, loss = 0.00961008\r\n",
      "Batch 3, loss = 0.0103932\r\n",
      "Batch 3, loss = 0.0101413\r\n",
      "Batch 3, loss = 0.00993649\r\n",
      "Batch 3, loss = 0.0101155\r\n",
      "Batch 3, loss = 0.0103679\r\n",
      "Batch 3, loss = 0.0101035\r\n",
      "Batch 3, loss = 0.0100854\r\n",
      "Batch 3, loss = 0.00983509\r\n",
      "Batch 3, loss = 0.00963998\r\n",
      "Batch 3, loss = 0.00958064\r\n",
      "Batch 3, loss = 0.0105444\r\n",
      "Batch 3, loss = 0.0104419\r\n",
      "Batch 3, loss = 0.0099154\r\n",
      "Batch 3, loss = 0.0092118\r\n",
      "Batch 3, loss = 0.0097413\r\n",
      "Batch 3, loss = 0.00971739\r\n",
      "Batch 3, loss = 0.00974267\r\n",
      "Batch 3, loss = 0.0102133\r\n",
      "Batch 3, loss = 0.010542\r\n",
      "Batch 3, loss = 0.00953141\r\n",
      "Batch 3, loss = 0.0104378\r\n",
      "Batch 3, loss = 0.0107075\r\n",
      "Batch 3, loss = 0.00941875\r\n",
      "Batch 3, loss = 0.00978815\r\n",
      "Batch 3, loss = 0.00974486\r\n",
      "Batch 3, loss = 0.00985153\r\n",
      "Batch 3, loss = 0.00998786\r\n",
      "Batch 3, loss = 0.00998568\r\n",
      "Batch 3, loss = 0.00994011\r\n",
      "Batch 3, loss = 0.00997482\r\n",
      "Batch 3, loss = 0.0102614\r\n",
      "Batch 3, loss = 0.00970271\r\n",
      "Batch 3, loss = 0.00941912\r\n",
      "Batch 3, loss = 0.0104025\r\n",
      "Batch 3, loss = 0.00983478\r\n",
      "Batch 3, loss = 0.00967896\r\n",
      "Batch 3, loss = 0.0106589\r\n",
      "Batch 3, loss = 0.00977467\r\n",
      "Batch 3, loss = 0.0105188\r\n",
      "Batch 3, loss = 0.00978854\r\n",
      "Batch 3, loss = 0.00958116\r\n",
      "Batch 3, loss = 0.00990993\r\n",
      "Batch 3, loss = 0.00996057\r\n",
      "Batch 3, loss = 0.00999409\r\n",
      "Batch 3, loss = 0.00957556\r\n",
      "Batch 3, loss = 0.0097228\r\n",
      "Batch 3, loss = 0.00989254\r\n",
      "Batch 3, loss = 0.00959422\r\n",
      "Batch 3, loss = 0.0100274\r\n",
      "Batch 3, loss = 0.00942379\r\n",
      "Batch 3, loss = 0.0101495\r\n",
      "Batch 3, loss = 0.00935208\r\n",
      "Batch 3, loss = 0.00959651\r\n",
      "Batch 3, loss = 0.0106419\r\n",
      "Batch 3, loss = 0.0103855\r\n",
      "Batch 3, loss = 0.0104327\r\n",
      "Batch 3, loss = 0.0105444\r\n",
      "Batch 3, loss = 0.010545\r\n",
      "Batch 3, loss = 0.00918817\r\n",
      "Batch 3, loss = 0.0102999\r\n",
      "Batch 3, loss = 0.00955119\r\n",
      "Batch 3, loss = 0.0093046\r\n",
      "Batch 3, loss = 0.010172\r\n",
      "Batch 3, loss = 0.00935569\r\n",
      "Batch 3, loss = 0.00913978\r\n",
      "Batch 3, loss = 0.0102677\r\n",
      "Batch 3, loss = 0.00919225\r\n",
      "Batch 3, loss = 0.0093193\r\n",
      "Batch 3, loss = 0.0100226\r\n",
      "Batch 3, loss = 0.00941641\r\n",
      "Batch 3, loss = 0.00993558\r\n",
      "Batch 3, loss = 0.00977336\r\n",
      "Batch 3, loss = 0.0105238\r\n",
      "Batch 3, loss = 0.0103626\r\n",
      "Batch 3, loss = 0.00954763\r\n",
      "Batch 3, loss = 0.00982931\r\n",
      "Batch 3, loss = 0.00923184\r\n",
      "Batch 3, loss = 0.00968352\r\n",
      "Batch 3, loss = 0.0101713\r\n",
      "Batch 3, loss = 0.010058\r\n",
      "Batch 3, loss = 0.00929719\r\n",
      "Batch 3, loss = 0.00950997\r\n",
      "Batch 3, loss = 0.00986729\r\n",
      "Batch 3, loss = 0.00997283\r\n",
      "Batch 3, loss = 0.0100032\r\n",
      "Batch 3, loss = 0.00926699\r\n",
      "Batch 3, loss = 0.0106061\r\n",
      "Batch 3, loss = 0.00980864\r\n",
      "Batch 3, loss = 0.00991424\r\n",
      "Batch 3, loss = 0.00998448\r\n",
      "Batch 3, loss = 0.00931214\r\n",
      "Batch 3, loss = 0.00945166\r\n",
      "Batch 3, loss = 0.00968032\r\n",
      "Batch 3, loss = 0.0101471\r\n",
      "Batch 3, loss = 0.0103083\r\n",
      "Batch 3, loss = 0.0100056\r\n",
      "Batch 4, label = 68\r\n",
      "Batch 4, loss = 0.010047\r\n",
      "Batch 4, loss = 0.00961618\r\n",
      "Batch 4, loss = 0.0102093\r\n",
      "Batch 4, loss = 0.0100273\r\n",
      "Batch 4, loss = 0.00961008\r\n",
      "Batch 4, loss = 0.0103932\r\n",
      "Batch 4, loss = 0.0101413\r\n",
      "Batch 4, loss = 0.00993649\r\n",
      "Batch 4, loss = 0.0101155\r\n",
      "Batch 4, loss = 0.0103679\r\n",
      "Batch 4, loss = 0.0101035\r\n",
      "Batch 4, loss = 0.0100854\r\n",
      "Batch 4, loss = 0.00983509\r\n",
      "Batch 4, loss = 0.00963998\r\n",
      "Batch 4, loss = 0.00958064\r\n",
      "Batch 4, loss = 0.0105444\r\n",
      "Batch 4, loss = 0.0104419\r\n",
      "Batch 4, loss = 0.0099154\r\n",
      "Batch 4, loss = 0.0092118\r\n",
      "Batch 4, loss = 0.0097413\r\n",
      "Batch 4, loss = 0.00971739\r\n",
      "Batch 4, loss = 0.00974267\r\n",
      "Batch 4, loss = 0.0102133\r\n",
      "Batch 4, loss = 0.010542\r\n",
      "Batch 4, loss = 0.00953141\r\n",
      "Batch 4, loss = 0.0104378\r\n",
      "Batch 4, loss = 0.0107075\r\n",
      "Batch 4, loss = 0.00941875\r\n",
      "Batch 4, loss = 0.00978815\r\n",
      "Batch 4, loss = 0.00974486\r\n",
      "Batch 4, loss = 0.00985153\r\n",
      "Batch 4, loss = 0.00998786\r\n",
      "Batch 4, loss = 0.00998568\r\n",
      "Batch 4, loss = 0.00994011\r\n",
      "Batch 4, loss = 0.00997482\r\n",
      "Batch 4, loss = 0.0102614\r\n",
      "Batch 4, loss = 0.00970271\r\n",
      "Batch 4, loss = 0.00941912\r\n",
      "Batch 4, loss = 0.0104025\r\n",
      "Batch 4, loss = 0.00983478\r\n",
      "Batch 4, loss = 0.00967896\r\n",
      "Batch 4, loss = 0.0106589\r\n",
      "Batch 4, loss = 0.00977467\r\n",
      "Batch 4, loss = 0.0105188\r\n",
      "Batch 4, loss = 0.00978854\r\n",
      "Batch 4, loss = 0.00958116\r\n",
      "Batch 4, loss = 0.00990993\r\n",
      "Batch 4, loss = 0.00996057\r\n",
      "Batch 4, loss = 0.00999409\r\n",
      "Batch 4, loss = 0.00957556\r\n",
      "Batch 4, loss = 0.0097228\r\n",
      "Batch 4, loss = 0.00989254\r\n",
      "Batch 4, loss = 0.00959422\r\n",
      "Batch 4, loss = 0.0100274\r\n",
      "Batch 4, loss = 0.00942379\r\n",
      "Batch 4, loss = 0.0101495\r\n",
      "Batch 4, loss = 0.00935208\r\n",
      "Batch 4, loss = 0.00959651\r\n",
      "Batch 4, loss = 0.0106419\r\n",
      "Batch 4, loss = 0.0103855\r\n",
      "Batch 4, loss = 0.0104327\r\n",
      "Batch 4, loss = 0.0105444\r\n",
      "Batch 4, loss = 0.010545\r\n",
      "Batch 4, loss = 0.00918817\r\n",
      "Batch 4, loss = 0.0102999\r\n",
      "Batch 4, loss = 0.00955119\r\n",
      "Batch 4, loss = 0.0093046\r\n",
      "Batch 4, loss = 0.010172\r\n",
      "Batch 4, loss = 0.00935569\r\n",
      "Batch 4, loss = 0.00913978\r\n",
      "Batch 4, loss = 0.0102677\r\n",
      "Batch 4, loss = 0.00919225\r\n",
      "Batch 4, loss = 0.0093193\r\n",
      "Batch 4, loss = 0.0100226\r\n",
      "Batch 4, loss = 0.00941641\r\n",
      "Batch 4, loss = 0.00993558\r\n",
      "Batch 4, loss = 0.00977336\r\n",
      "Batch 4, loss = 0.0105238\r\n",
      "Batch 4, loss = 0.0103626\r\n",
      "Batch 4, loss = 0.00954763\r\n",
      "Batch 4, loss = 0.00982931\r\n",
      "Batch 4, loss = 0.00923184\r\n",
      "Batch 4, loss = 0.00968352\r\n",
      "Batch 4, loss = 0.0101713\r\n",
      "Batch 4, loss = 0.010058\r\n",
      "Batch 4, loss = 0.00929719\r\n",
      "Batch 4, loss = 0.00950997\r\n",
      "Batch 4, loss = 0.00986729\r\n",
      "Batch 4, loss = 0.00997283\r\n",
      "Batch 4, loss = 0.0100032\r\n",
      "Batch 4, loss = 0.00926699\r\n",
      "Batch 4, loss = 0.0106061\r\n",
      "Batch 4, loss = 0.00980864\r\n",
      "Batch 4, loss = 0.00991424\r\n",
      "Batch 4, loss = 0.00998448\r\n",
      "Batch 4, loss = 0.00931214\r\n",
      "Batch 4, loss = 0.00945166\r\n",
      "Batch 4, loss = 0.00968032\r\n",
      "Batch 4, loss = 0.0101471\r\n",
      "Batch 4, loss = 0.0103083\r\n",
      "Batch 4, loss = 0.0100056\r\n",
      "Batch 5, label = 38\r\n",
      "Batch 5, loss = 0.010047\r\n",
      "Batch 5, loss = 0.00961618\r\n",
      "Batch 5, loss = 0.0102093\r\n",
      "Batch 5, loss = 0.0100273\r\n",
      "Batch 5, loss = 0.00961008\r\n",
      "Batch 5, loss = 0.0103932\r\n",
      "Batch 5, loss = 0.0101413\r\n",
      "Batch 5, loss = 0.00993649\r\n",
      "Batch 5, loss = 0.0101155\r\n",
      "Batch 5, loss = 0.0103679\r\n",
      "Batch 5, loss = 0.0101035\r\n",
      "Batch 5, loss = 0.0100854\r\n",
      "Batch 5, loss = 0.00983509\r\n",
      "Batch 5, loss = 0.00963998\r\n",
      "Batch 5, loss = 0.00958064\r\n",
      "Batch 5, loss = 0.0105444\r\n",
      "Batch 5, loss = 0.0104419\r\n",
      "Batch 5, loss = 0.0099154\r\n",
      "Batch 5, loss = 0.0092118\r\n",
      "Batch 5, loss = 0.0097413\r\n",
      "Batch 5, loss = 0.00971739\r\n",
      "Batch 5, loss = 0.00974267\r\n",
      "Batch 5, loss = 0.0102133\r\n",
      "Batch 5, loss = 0.010542\r\n",
      "Batch 5, loss = 0.00953141\r\n",
      "Batch 5, loss = 0.0104378\r\n",
      "Batch 5, loss = 0.0107075\r\n",
      "Batch 5, loss = 0.00941875\r\n",
      "Batch 5, loss = 0.00978815\r\n",
      "Batch 5, loss = 0.00974486\r\n",
      "Batch 5, loss = 0.00985153\r\n",
      "Batch 5, loss = 0.00998786\r\n",
      "Batch 5, loss = 0.00998568\r\n",
      "Batch 5, loss = 0.00994011\r\n",
      "Batch 5, loss = 0.00997482\r\n",
      "Batch 5, loss = 0.0102614\r\n",
      "Batch 5, loss = 0.00970271\r\n",
      "Batch 5, loss = 0.00941912\r\n",
      "Batch 5, loss = 0.0104025\r\n",
      "Batch 5, loss = 0.00983478\r\n",
      "Batch 5, loss = 0.00967896\r\n",
      "Batch 5, loss = 0.0106589\r\n",
      "Batch 5, loss = 0.00977467\r\n",
      "Batch 5, loss = 0.0105188\r\n",
      "Batch 5, loss = 0.00978854\r\n",
      "Batch 5, loss = 0.00958116\r\n",
      "Batch 5, loss = 0.00990993\r\n",
      "Batch 5, loss = 0.00996057\r\n",
      "Batch 5, loss = 0.00999409\r\n",
      "Batch 5, loss = 0.00957556\r\n",
      "Batch 5, loss = 0.0097228\r\n",
      "Batch 5, loss = 0.00989254\r\n",
      "Batch 5, loss = 0.00959422\r\n",
      "Batch 5, loss = 0.0100274\r\n",
      "Batch 5, loss = 0.00942379\r\n",
      "Batch 5, loss = 0.0101495\r\n",
      "Batch 5, loss = 0.00935208\r\n",
      "Batch 5, loss = 0.00959651\r\n",
      "Batch 5, loss = 0.0106419\r\n",
      "Batch 5, loss = 0.0103855\r\n",
      "Batch 5, loss = 0.0104327\r\n",
      "Batch 5, loss = 0.0105444\r\n",
      "Batch 5, loss = 0.010545\r\n",
      "Batch 5, loss = 0.00918817\r\n",
      "Batch 5, loss = 0.0102999\r\n",
      "Batch 5, loss = 0.00955119\r\n",
      "Batch 5, loss = 0.0093046\r\n",
      "Batch 5, loss = 0.010172\r\n",
      "Batch 5, loss = 0.00935569\r\n",
      "Batch 5, loss = 0.00913978\r\n",
      "Batch 5, loss = 0.0102677\r\n",
      "Batch 5, loss = 0.00919225\r\n",
      "Batch 5, loss = 0.0093193\r\n",
      "Batch 5, loss = 0.0100226\r\n",
      "Batch 5, loss = 0.00941641\r\n",
      "Batch 5, loss = 0.00993558\r\n",
      "Batch 5, loss = 0.00977336\r\n",
      "Batch 5, loss = 0.0105238\r\n",
      "Batch 5, loss = 0.0103626\r\n",
      "Batch 5, loss = 0.00954763\r\n",
      "Batch 5, loss = 0.00982931\r\n",
      "Batch 5, loss = 0.00923184\r\n",
      "Batch 5, loss = 0.00968352\r\n",
      "Batch 5, loss = 0.0101713\r\n",
      "Batch 5, loss = 0.010058\r\n",
      "Batch 5, loss = 0.00929719\r\n",
      "Batch 5, loss = 0.00950997\r\n",
      "Batch 5, loss = 0.00986729\r\n",
      "Batch 5, loss = 0.00997283\r\n",
      "Batch 5, loss = 0.0100032\r\n",
      "Batch 5, loss = 0.00926699\r\n",
      "Batch 5, loss = 0.0106061\r\n",
      "Batch 5, loss = 0.00980864\r\n",
      "Batch 5, loss = 0.00991424\r\n",
      "Batch 5, loss = 0.00998448\r\n",
      "Batch 5, loss = 0.00931214\r\n",
      "Batch 5, loss = 0.00945166\r\n",
      "Batch 5, loss = 0.00968032\r\n",
      "Batch 5, loss = 0.0101471\r\n",
      "Batch 5, loss = 0.0103083\r\n",
      "Batch 5, loss = 0.0100056\r\n",
      "Batch 6, label = 71\r\n",
      "Batch 6, loss = 0.010047\r\n",
      "Batch 6, loss = 0.00961618\r\n",
      "Batch 6, loss = 0.0102093\r\n",
      "Batch 6, loss = 0.0100273\r\n",
      "Batch 6, loss = 0.00961008\r\n",
      "Batch 6, loss = 0.0103932\r\n",
      "Batch 6, loss = 0.0101413\r\n",
      "Batch 6, loss = 0.00993649\r\n",
      "Batch 6, loss = 0.0101155\r\n",
      "Batch 6, loss = 0.0103679\r\n",
      "Batch 6, loss = 0.0101035\r\n",
      "Batch 6, loss = 0.0100854\r\n",
      "Batch 6, loss = 0.00983509\r\n",
      "Batch 6, loss = 0.00963998\r\n",
      "Batch 6, loss = 0.00958064\r\n",
      "Batch 6, loss = 0.0105444\r\n",
      "Batch 6, loss = 0.0104419\r\n",
      "Batch 6, loss = 0.0099154\r\n",
      "Batch 6, loss = 0.0092118\r\n",
      "Batch 6, loss = 0.0097413\r\n",
      "Batch 6, loss = 0.00971739\r\n",
      "Batch 6, loss = 0.00974267\r\n",
      "Batch 6, loss = 0.0102133\r\n",
      "Batch 6, loss = 0.010542\r\n",
      "Batch 6, loss = 0.00953141\r\n",
      "Batch 6, loss = 0.0104378\r\n",
      "Batch 6, loss = 0.0107075\r\n",
      "Batch 6, loss = 0.00941875\r\n",
      "Batch 6, loss = 0.00978815\r\n",
      "Batch 6, loss = 0.00974486\r\n",
      "Batch 6, loss = 0.00985153\r\n",
      "Batch 6, loss = 0.00998786\r\n",
      "Batch 6, loss = 0.00998568\r\n",
      "Batch 6, loss = 0.00994011\r\n",
      "Batch 6, loss = 0.00997482\r\n",
      "Batch 6, loss = 0.0102614\r\n",
      "Batch 6, loss = 0.00970271\r\n",
      "Batch 6, loss = 0.00941912\r\n",
      "Batch 6, loss = 0.0104025\r\n",
      "Batch 6, loss = 0.00983478\r\n",
      "Batch 6, loss = 0.00967896\r\n",
      "Batch 6, loss = 0.0106589\r\n",
      "Batch 6, loss = 0.00977467\r\n",
      "Batch 6, loss = 0.0105188\r\n",
      "Batch 6, loss = 0.00978854\r\n",
      "Batch 6, loss = 0.00958116\r\n",
      "Batch 6, loss = 0.00990993\r\n",
      "Batch 6, loss = 0.00996057\r\n",
      "Batch 6, loss = 0.00999409\r\n",
      "Batch 6, loss = 0.00957556\r\n",
      "Batch 6, loss = 0.0097228\r\n",
      "Batch 6, loss = 0.00989254\r\n",
      "Batch 6, loss = 0.00959422\r\n",
      "Batch 6, loss = 0.0100274\r\n",
      "Batch 6, loss = 0.00942379\r\n",
      "Batch 6, loss = 0.0101495\r\n",
      "Batch 6, loss = 0.00935208\r\n",
      "Batch 6, loss = 0.00959651\r\n",
      "Batch 6, loss = 0.0106419\r\n",
      "Batch 6, loss = 0.0103855\r\n",
      "Batch 6, loss = 0.0104327\r\n",
      "Batch 6, loss = 0.0105444\r\n",
      "Batch 6, loss = 0.010545\r\n",
      "Batch 6, loss = 0.00918817\r\n",
      "Batch 6, loss = 0.0102999\r\n",
      "Batch 6, loss = 0.00955119\r\n",
      "Batch 6, loss = 0.0093046\r\n",
      "Batch 6, loss = 0.010172\r\n",
      "Batch 6, loss = 0.00935569\r\n",
      "Batch 6, loss = 0.00913978\r\n",
      "Batch 6, loss = 0.0102677\r\n",
      "Batch 6, loss = 0.00919225\r\n",
      "Batch 6, loss = 0.0093193\r\n",
      "Batch 6, loss = 0.0100226\r\n",
      "Batch 6, loss = 0.00941641\r\n",
      "Batch 6, loss = 0.00993558\r\n",
      "Batch 6, loss = 0.00977336\r\n",
      "Batch 6, loss = 0.0105238\r\n",
      "Batch 6, loss = 0.0103626\r\n",
      "Batch 6, loss = 0.00954763\r\n",
      "Batch 6, loss = 0.00982931\r\n",
      "Batch 6, loss = 0.00923184\r\n",
      "Batch 6, loss = 0.00968352\r\n",
      "Batch 6, loss = 0.0101713\r\n",
      "Batch 6, loss = 0.010058\r\n",
      "Batch 6, loss = 0.00929719\r\n",
      "Batch 6, loss = 0.00950997\r\n",
      "Batch 6, loss = 0.00986729\r\n",
      "Batch 6, loss = 0.00997283\r\n",
      "Batch 6, loss = 0.0100032\r\n",
      "Batch 6, loss = 0.00926699\r\n",
      "Batch 6, loss = 0.0106061\r\n",
      "Batch 6, loss = 0.00980864\r\n",
      "Batch 6, loss = 0.00991424\r\n",
      "Batch 6, loss = 0.00998448\r\n",
      "Batch 6, loss = 0.00931214\r\n",
      "Batch 6, loss = 0.00945166\r\n",
      "Batch 6, loss = 0.00968032\r\n",
      "Batch 6, loss = 0.0101471\r\n",
      "Batch 6, loss = 0.0103083\r\n",
      "Batch 6, loss = 0.0100056\r\n",
      "Batch 7, label = 74\r\n",
      "Batch 7, loss = 0.010047\r\n",
      "Batch 7, loss = 0.00961618\r\n",
      "Batch 7, loss = 0.0102093\r\n",
      "Batch 7, loss = 0.0100273\r\n",
      "Batch 7, loss = 0.00961008\r\n",
      "Batch 7, loss = 0.0103932\r\n",
      "Batch 7, loss = 0.0101413\r\n",
      "Batch 7, loss = 0.00993649\r\n",
      "Batch 7, loss = 0.0101155\r\n",
      "Batch 7, loss = 0.0103679\r\n",
      "Batch 7, loss = 0.0101035\r\n",
      "Batch 7, loss = 0.0100854\r\n",
      "Batch 7, loss = 0.00983509\r\n",
      "Batch 7, loss = 0.00963998\r\n",
      "Batch 7, loss = 0.00958064\r\n",
      "Batch 7, loss = 0.0105444\r\n",
      "Batch 7, loss = 0.0104419\r\n",
      "Batch 7, loss = 0.0099154\r\n",
      "Batch 7, loss = 0.0092118\r\n",
      "Batch 7, loss = 0.0097413\r\n",
      "Batch 7, loss = 0.00971739\r\n",
      "Batch 7, loss = 0.00974267\r\n",
      "Batch 7, loss = 0.0102133\r\n",
      "Batch 7, loss = 0.010542\r\n",
      "Batch 7, loss = 0.00953141\r\n",
      "Batch 7, loss = 0.0104378\r\n",
      "Batch 7, loss = 0.0107075\r\n",
      "Batch 7, loss = 0.00941875\r\n",
      "Batch 7, loss = 0.00978815\r\n",
      "Batch 7, loss = 0.00974486\r\n",
      "Batch 7, loss = 0.00985153\r\n",
      "Batch 7, loss = 0.00998786\r\n",
      "Batch 7, loss = 0.00998568\r\n",
      "Batch 7, loss = 0.00994011\r\n",
      "Batch 7, loss = 0.00997482\r\n",
      "Batch 7, loss = 0.0102614\r\n",
      "Batch 7, loss = 0.00970271\r\n",
      "Batch 7, loss = 0.00941912\r\n",
      "Batch 7, loss = 0.0104025\r\n",
      "Batch 7, loss = 0.00983478\r\n",
      "Batch 7, loss = 0.00967896\r\n",
      "Batch 7, loss = 0.0106589\r\n",
      "Batch 7, loss = 0.00977467\r\n",
      "Batch 7, loss = 0.0105188\r\n",
      "Batch 7, loss = 0.00978854\r\n",
      "Batch 7, loss = 0.00958116\r\n",
      "Batch 7, loss = 0.00990993\r\n",
      "Batch 7, loss = 0.00996057\r\n",
      "Batch 7, loss = 0.00999409\r\n",
      "Batch 7, loss = 0.00957556\r\n",
      "Batch 7, loss = 0.0097228\r\n",
      "Batch 7, loss = 0.00989254\r\n",
      "Batch 7, loss = 0.00959422\r\n",
      "Batch 7, loss = 0.0100274\r\n",
      "Batch 7, loss = 0.00942379\r\n",
      "Batch 7, loss = 0.0101495\r\n",
      "Batch 7, loss = 0.00935208\r\n",
      "Batch 7, loss = 0.00959651\r\n",
      "Batch 7, loss = 0.0106419\r\n",
      "Batch 7, loss = 0.0103855\r\n",
      "Batch 7, loss = 0.0104327\r\n",
      "Batch 7, loss = 0.0105444\r\n",
      "Batch 7, loss = 0.010545\r\n",
      "Batch 7, loss = 0.00918817\r\n",
      "Batch 7, loss = 0.0102999\r\n",
      "Batch 7, loss = 0.00955119\r\n",
      "Batch 7, loss = 0.0093046\r\n",
      "Batch 7, loss = 0.010172\r\n",
      "Batch 7, loss = 0.00935569\r\n",
      "Batch 7, loss = 0.00913978\r\n",
      "Batch 7, loss = 0.0102677\r\n",
      "Batch 7, loss = 0.00919225\r\n",
      "Batch 7, loss = 0.0093193\r\n",
      "Batch 7, loss = 0.0100226\r\n",
      "Batch 7, loss = 0.00941641\r\n",
      "Batch 7, loss = 0.00993558\r\n",
      "Batch 7, loss = 0.00977336\r\n",
      "Batch 7, loss = 0.0105238\r\n",
      "Batch 7, loss = 0.0103626\r\n",
      "Batch 7, loss = 0.00954763\r\n",
      "Batch 7, loss = 0.00982931\r\n",
      "Batch 7, loss = 0.00923184\r\n",
      "Batch 7, loss = 0.00968352\r\n",
      "Batch 7, loss = 0.0101713\r\n",
      "Batch 7, loss = 0.010058\r\n",
      "Batch 7, loss = 0.00929719\r\n",
      "Batch 7, loss = 0.00950997\r\n",
      "Batch 7, loss = 0.00986729\r\n",
      "Batch 7, loss = 0.00997283\r\n",
      "Batch 7, loss = 0.0100032\r\n",
      "Batch 7, loss = 0.00926699\r\n",
      "Batch 7, loss = 0.0106061\r\n",
      "Batch 7, loss = 0.00980864\r\n",
      "Batch 7, loss = 0.00991424\r\n",
      "Batch 7, loss = 0.00998448\r\n",
      "Batch 7, loss = 0.00931214\r\n",
      "Batch 7, loss = 0.00945166\r\n",
      "Batch 7, loss = 0.00968032\r\n",
      "Batch 7, loss = 0.0101471\r\n",
      "Batch 7, loss = 0.0103083\r\n",
      "Batch 7, loss = 0.0100056\r\n",
      "Batch 8, label = 90\r\n",
      "Batch 8, loss = 0.010047\r\n",
      "Batch 8, loss = 0.00961618\r\n",
      "Batch 8, loss = 0.0102093\r\n",
      "Batch 8, loss = 0.0100273\r\n",
      "Batch 8, loss = 0.00961008\r\n",
      "Batch 8, loss = 0.0103932\r\n",
      "Batch 8, loss = 0.0101413\r\n",
      "Batch 8, loss = 0.00993649\r\n",
      "Batch 8, loss = 0.0101155\r\n",
      "Batch 8, loss = 0.0103679\r\n",
      "Batch 8, loss = 0.0101035\r\n",
      "Batch 8, loss = 0.0100854\r\n",
      "Batch 8, loss = 0.00983509\r\n",
      "Batch 8, loss = 0.00963998\r\n",
      "Batch 8, loss = 0.00958064\r\n",
      "Batch 8, loss = 0.0105444\r\n",
      "Batch 8, loss = 0.0104419\r\n",
      "Batch 8, loss = 0.0099154\r\n",
      "Batch 8, loss = 0.0092118\r\n",
      "Batch 8, loss = 0.0097413\r\n",
      "Batch 8, loss = 0.00971739\r\n",
      "Batch 8, loss = 0.00974267\r\n",
      "Batch 8, loss = 0.0102133\r\n",
      "Batch 8, loss = 0.010542\r\n",
      "Batch 8, loss = 0.00953141\r\n",
      "Batch 8, loss = 0.0104378\r\n",
      "Batch 8, loss = 0.0107075\r\n",
      "Batch 8, loss = 0.00941875\r\n",
      "Batch 8, loss = 0.00978815\r\n",
      "Batch 8, loss = 0.00974486\r\n",
      "Batch 8, loss = 0.00985153\r\n",
      "Batch 8, loss = 0.00998786\r\n",
      "Batch 8, loss = 0.00998568\r\n",
      "Batch 8, loss = 0.00994011\r\n",
      "Batch 8, loss = 0.00997482\r\n",
      "Batch 8, loss = 0.0102614\r\n",
      "Batch 8, loss = 0.00970271\r\n",
      "Batch 8, loss = 0.00941912\r\n",
      "Batch 8, loss = 0.0104025\r\n",
      "Batch 8, loss = 0.00983478\r\n",
      "Batch 8, loss = 0.00967896\r\n",
      "Batch 8, loss = 0.0106589\r\n",
      "Batch 8, loss = 0.00977467\r\n",
      "Batch 8, loss = 0.0105188\r\n",
      "Batch 8, loss = 0.00978854\r\n",
      "Batch 8, loss = 0.00958116\r\n",
      "Batch 8, loss = 0.00990993\r\n",
      "Batch 8, loss = 0.00996057\r\n",
      "Batch 8, loss = 0.00999409\r\n",
      "Batch 8, loss = 0.00957556\r\n",
      "Batch 8, loss = 0.0097228\r\n",
      "Batch 8, loss = 0.00989254\r\n",
      "Batch 8, loss = 0.00959422\r\n",
      "Batch 8, loss = 0.0100274\r\n",
      "Batch 8, loss = 0.00942379\r\n",
      "Batch 8, loss = 0.0101495\r\n",
      "Batch 8, loss = 0.00935208\r\n",
      "Batch 8, loss = 0.00959651\r\n",
      "Batch 8, loss = 0.0106419\r\n",
      "Batch 8, loss = 0.0103855\r\n",
      "Batch 8, loss = 0.0104327\r\n",
      "Batch 8, loss = 0.0105444\r\n",
      "Batch 8, loss = 0.010545\r\n",
      "Batch 8, loss = 0.00918817\r\n",
      "Batch 8, loss = 0.0102999\r\n",
      "Batch 8, loss = 0.00955119\r\n",
      "Batch 8, loss = 0.0093046\r\n",
      "Batch 8, loss = 0.010172\r\n",
      "Batch 8, loss = 0.00935569\r\n",
      "Batch 8, loss = 0.00913978\r\n",
      "Batch 8, loss = 0.0102677\r\n",
      "Batch 8, loss = 0.00919225\r\n",
      "Batch 8, loss = 0.0093193\r\n",
      "Batch 8, loss = 0.0100226\r\n",
      "Batch 8, loss = 0.00941641\r\n",
      "Batch 8, loss = 0.00993558\r\n",
      "Batch 8, loss = 0.00977336\r\n",
      "Batch 8, loss = 0.0105238\r\n",
      "Batch 8, loss = 0.0103626\r\n",
      "Batch 8, loss = 0.00954763\r\n",
      "Batch 8, loss = 0.00982931\r\n",
      "Batch 8, loss = 0.00923184\r\n",
      "Batch 8, loss = 0.00968352\r\n",
      "Batch 8, loss = 0.0101713\r\n",
      "Batch 8, loss = 0.010058\r\n",
      "Batch 8, loss = 0.00929719\r\n",
      "Batch 8, loss = 0.00950997\r\n",
      "Batch 8, loss = 0.00986729\r\n",
      "Batch 8, loss = 0.00997283\r\n",
      "Batch 8, loss = 0.0100032\r\n",
      "Batch 8, loss = 0.00926699\r\n",
      "Batch 8, loss = 0.0106061\r\n",
      "Batch 8, loss = 0.00980864\r\n",
      "Batch 8, loss = 0.00991424\r\n",
      "Batch 8, loss = 0.00998448\r\n",
      "Batch 8, loss = 0.00931214\r\n",
      "Batch 8, loss = 0.00945166\r\n",
      "Batch 8, loss = 0.00968032\r\n",
      "Batch 8, loss = 0.0101471\r\n",
      "Batch 8, loss = 0.0103083\r\n",
      "Batch 8, loss = 0.0100056\r\n",
      "Batch 9, label = 7\r\n",
      "Batch 9, loss = 0.010047\r\n",
      "Batch 9, loss = 0.00961618\r\n",
      "Batch 9, loss = 0.0102093\r\n",
      "Batch 9, loss = 0.0100273\r\n",
      "Batch 9, loss = 0.00961008\r\n",
      "Batch 9, loss = 0.0103932\r\n",
      "Batch 9, loss = 0.0101413\r\n",
      "Batch 9, loss = 0.00993649\r\n",
      "Batch 9, loss = 0.0101155\r\n",
      "Batch 9, loss = 0.0103679\r\n",
      "Batch 9, loss = 0.0101035\r\n",
      "Batch 9, loss = 0.0100854\r\n",
      "Batch 9, loss = 0.00983509\r\n",
      "Batch 9, loss = 0.00963998\r\n",
      "Batch 9, loss = 0.00958064\r\n",
      "Batch 9, loss = 0.0105444\r\n",
      "Batch 9, loss = 0.0104419\r\n",
      "Batch 9, loss = 0.0099154\r\n",
      "Batch 9, loss = 0.0092118\r\n",
      "Batch 9, loss = 0.0097413\r\n",
      "Batch 9, loss = 0.00971739\r\n",
      "Batch 9, loss = 0.00974267\r\n",
      "Batch 9, loss = 0.0102133\r\n",
      "Batch 9, loss = 0.010542\r\n",
      "Batch 9, loss = 0.00953141\r\n",
      "Batch 9, loss = 0.0104378\r\n",
      "Batch 9, loss = 0.0107075\r\n",
      "Batch 9, loss = 0.00941875\r\n",
      "Batch 9, loss = 0.00978815\r\n",
      "Batch 9, loss = 0.00974486\r\n",
      "Batch 9, loss = 0.00985153\r\n",
      "Batch 9, loss = 0.00998786\r\n",
      "Batch 9, loss = 0.00998568\r\n",
      "Batch 9, loss = 0.00994011\r\n",
      "Batch 9, loss = 0.00997482\r\n",
      "Batch 9, loss = 0.0102614\r\n",
      "Batch 9, loss = 0.00970271\r\n",
      "Batch 9, loss = 0.00941912\r\n",
      "Batch 9, loss = 0.0104025\r\n",
      "Batch 9, loss = 0.00983478\r\n",
      "Batch 9, loss = 0.00967896\r\n",
      "Batch 9, loss = 0.0106589\r\n",
      "Batch 9, loss = 0.00977467\r\n",
      "Batch 9, loss = 0.0105188\r\n",
      "Batch 9, loss = 0.00978854\r\n",
      "Batch 9, loss = 0.00958116\r\n",
      "Batch 9, loss = 0.00990993\r\n",
      "Batch 9, loss = 0.00996057\r\n",
      "Batch 9, loss = 0.00999409\r\n",
      "Batch 9, loss = 0.00957556\r\n",
      "Batch 9, loss = 0.0097228\r\n",
      "Batch 9, loss = 0.00989254\r\n",
      "Batch 9, loss = 0.00959422\r\n",
      "Batch 9, loss = 0.0100274\r\n",
      "Batch 9, loss = 0.00942379\r\n",
      "Batch 9, loss = 0.0101495\r\n",
      "Batch 9, loss = 0.00935208\r\n",
      "Batch 9, loss = 0.00959651\r\n",
      "Batch 9, loss = 0.0106419\r\n",
      "Batch 9, loss = 0.0103855\r\n",
      "Batch 9, loss = 0.0104327\r\n",
      "Batch 9, loss = 0.0105444\r\n",
      "Batch 9, loss = 0.010545\r\n",
      "Batch 9, loss = 0.00918817\r\n",
      "Batch 9, loss = 0.0102999\r\n",
      "Batch 9, loss = 0.00955119\r\n",
      "Batch 9, loss = 0.0093046\r\n",
      "Batch 9, loss = 0.010172\r\n",
      "Batch 9, loss = 0.00935569\r\n",
      "Batch 9, loss = 0.00913978\r\n",
      "Batch 9, loss = 0.0102677\r\n",
      "Batch 9, loss = 0.00919225\r\n",
      "Batch 9, loss = 0.0093193\r\n",
      "Batch 9, loss = 0.0100226\r\n",
      "Batch 9, loss = 0.00941641\r\n",
      "Batch 9, loss = 0.00993558\r\n",
      "Batch 9, loss = 0.00977336\r\n",
      "Batch 9, loss = 0.0105238\r\n",
      "Batch 9, loss = 0.0103626\r\n",
      "Batch 9, loss = 0.00954763\r\n",
      "Batch 9, loss = 0.00982931\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1000 /afs/cs.stanford.edu/u/anenberg/scr/CS231N/examples/allFrames/tmp.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7840\n"
     ]
    }
   ],
   "source": [
    "experiment_dir = '/afs/cs.stanford.edu/u/anenberg/scr/CS231N/examples/allFrames/'\n",
    "filename = 'tmp.out'\n",
    "\n",
    "import os, itertools, numpy as np\n",
    "count = 0\n",
    "n = 102 # number of classes + 1 (for header)\n",
    "\n",
    "def extract_label(line_block):\n",
    "    words = line_block[0].split()\n",
    "    return int(words[-1])\n",
    "\n",
    "def extract_scores(line_block):\n",
    "    score_lines = line_block[1:]\n",
    "    return np.array([float(score_line.strip().split()[-1]) for score_line in score_lines])\n",
    "    \n",
    "labels = []\n",
    "with open(os.path.join(experiment_dir, filename), 'r+') as f:\n",
    "    while True:\n",
    "        next_n_lines = list(itertools.islice(f, n))\n",
    "        if len(next_n_lines) < n:\n",
    "            break\n",
    "        count += 1\n",
    "\n",
    "        # get label\n",
    "        true_label = extract_label(next_n_lines)\n",
    "        # get scores\n",
    "        scores = extract_scores(next_n_lines)\n",
    "        predicted_label = np.argmax(scores)\n",
    "        \n",
    "        labels.append((true_label, predicted_label, np.max(scores)))\n",
    "    print count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(labels, columns = ['true', 'predicted', 'max_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>predicted</th>\n",
       "      <th>max_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0   </th>\n",
       "      <td> 32</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1   </th>\n",
       "      <td> 27</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2   </th>\n",
       "      <td> 65</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3   </th>\n",
       "      <td> 56</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4   </th>\n",
       "      <td> 68</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5   </th>\n",
       "      <td> 38</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6   </th>\n",
       "      <td> 71</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7   </th>\n",
       "      <td> 74</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8   </th>\n",
       "      <td> 90</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9   </th>\n",
       "      <td>  7</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10  </th>\n",
       "      <td> 89</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11  </th>\n",
       "      <td> 47</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12  </th>\n",
       "      <td> 26</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13  </th>\n",
       "      <td> 24</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14  </th>\n",
       "      <td> 42</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15  </th>\n",
       "      <td> 67</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16  </th>\n",
       "      <td> 47</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17  </th>\n",
       "      <td> 14</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18  </th>\n",
       "      <td>  1</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19  </th>\n",
       "      <td> 85</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20  </th>\n",
       "      <td> 11</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21  </th>\n",
       "      <td> 95</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22  </th>\n",
       "      <td> 30</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23  </th>\n",
       "      <td> 26</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24  </th>\n",
       "      <td> 86</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25  </th>\n",
       "      <td> 68</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26  </th>\n",
       "      <td> 74</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27  </th>\n",
       "      <td>  4</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28  </th>\n",
       "      <td> 44</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29  </th>\n",
       "      <td> 17</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7810</th>\n",
       "      <td>  6</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7811</th>\n",
       "      <td> 40</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7812</th>\n",
       "      <td> 47</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813</th>\n",
       "      <td>  9</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7814</th>\n",
       "      <td> 77</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815</th>\n",
       "      <td> 93</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7816</th>\n",
       "      <td> 20</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7817</th>\n",
       "      <td>  8</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7818</th>\n",
       "      <td> 10</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819</th>\n",
       "      <td> 52</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7820</th>\n",
       "      <td> 76</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7821</th>\n",
       "      <td> 43</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7822</th>\n",
       "      <td>  5</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7823</th>\n",
       "      <td> 81</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7824</th>\n",
       "      <td> 53</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7825</th>\n",
       "      <td> 60</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7826</th>\n",
       "      <td> 51</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7827</th>\n",
       "      <td> 75</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7828</th>\n",
       "      <td> 92</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7829</th>\n",
       "      <td> 10</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7830</th>\n",
       "      <td> 73</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7831</th>\n",
       "      <td> 92</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7832</th>\n",
       "      <td> 73</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7833</th>\n",
       "      <td>  7</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td> 96</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td> 11</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td> 23</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td> 69</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7838</th>\n",
       "      <td> 55</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7839</th>\n",
       "      <td> 50</td>\n",
       "      <td> 26</td>\n",
       "      <td> 0.010708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7840 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      true  predicted  max_score\n",
       "0       32         26   0.010708\n",
       "1       27         26   0.010708\n",
       "2       65         26   0.010708\n",
       "3       56         26   0.010708\n",
       "4       68         26   0.010708\n",
       "5       38         26   0.010708\n",
       "6       71         26   0.010708\n",
       "7       74         26   0.010708\n",
       "8       90         26   0.010708\n",
       "9        7         26   0.010708\n",
       "10      89         26   0.010708\n",
       "11      47         26   0.010708\n",
       "12      26         26   0.010708\n",
       "13      24         26   0.010708\n",
       "14      42         26   0.010708\n",
       "15      67         26   0.010708\n",
       "16      47         26   0.010708\n",
       "17      14         26   0.010708\n",
       "18       1         26   0.010708\n",
       "19      85         26   0.010708\n",
       "20      11         26   0.010708\n",
       "21      95         26   0.010708\n",
       "22      30         26   0.010708\n",
       "23      26         26   0.010708\n",
       "24      86         26   0.010708\n",
       "25      68         26   0.010708\n",
       "26      74         26   0.010708\n",
       "27       4         26   0.010708\n",
       "28      44         26   0.010708\n",
       "29      17         26   0.010708\n",
       "...    ...        ...        ...\n",
       "7810     6         26   0.010708\n",
       "7811    40         26   0.010708\n",
       "7812    47         26   0.010708\n",
       "7813     9         26   0.010708\n",
       "7814    77         26   0.010708\n",
       "7815    93         26   0.010708\n",
       "7816    20         26   0.010708\n",
       "7817     8         26   0.010708\n",
       "7818    10         26   0.010708\n",
       "7819    52         26   0.010708\n",
       "7820    76         26   0.010708\n",
       "7821    43         26   0.010708\n",
       "7822     5         26   0.010708\n",
       "7823    81         26   0.010708\n",
       "7824    53         26   0.010708\n",
       "7825    60         26   0.010708\n",
       "7826    51         26   0.010708\n",
       "7827    75         26   0.010708\n",
       "7828    92         26   0.010708\n",
       "7829    10         26   0.010708\n",
       "7830    73         26   0.010708\n",
       "7831    92         26   0.010708\n",
       "7832    73         26   0.010708\n",
       "7833     7         26   0.010708\n",
       "7834    96         26   0.010708\n",
       "7835    11         26   0.010708\n",
       "7836    23         26   0.010708\n",
       "7837    69         26   0.010708\n",
       "7838    55         26   0.010708\n",
       "7839    50         26   0.010708\n",
       "\n",
       "[7840 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "more /afs/cs.stanford.edu/u/anenberg/scr/CS231N/data/allFrames/lists/shuffle_sampled_test_list.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0305 10:53:54.335021 22019 caffe.cpp:134] Use GPU with device ID 1\n",
      "I0305 10:53:55.448482 22019 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer quick\n",
      "I0305 10:53:55.448731 22019 net.cpp:39] Initializing net from parameters: \n",
      "name: \"quick\"\n",
      "layers {\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  name: \"allFrames_shuffled_sampled\"\n",
      "  type: DATA\n",
      "  data_param {\n",
      "    source: \"./test_lmdb_shuffle_sampled\"\n",
      "    batch_size: 1\n",
      "    backend: LMDB\n",
      "  }\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  transform_param {\n",
      "    mean_file: \"./mean_shuffle_sampled.binaryproto\"\n",
      "  }\n",
      "}\n",
      "layers {\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  name: \"conv1\"\n",
      "  type: CONVOLUTION\n",
      "  blobs_lr: 1\n",
      "  blobs_lr: 2\n",
      "  convolution_param {\n",
      "    num_output: 32\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.0001\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layers {\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  name: \"pool1\"\n",
      "  type: POOLING\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layers {\n",
      "  bottom: \"pool1\"\n",
      "  top: \"pool1\"\n",
      "  name: \"relu1\"\n",
      "  type: RELU\n",
      "}\n",
      "layers {\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  name: \"conv2\"\n",
      "  type: CONVOLUTION\n",
      "  blobs_lr: 1\n",
      "  blobs_lr: 2\n",
      "  convolution_param {\n",
      "    num_output: 32\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layers {\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "  name: \"relu2\"\n",
      "  type: RELU\n",
      "}\n",
      "layers {\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  name: \"pool2\"\n",
      "  type: POOLING\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layers {\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  name: \"conv3\"\n",
      "  type: CONVOLUTION\n",
      "  blobs_lr: 1\n",
      "  blobs_lr: 2\n",
      "  convolution_param {\n",
      "    num_output: 64\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layers {\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "  name: \"relu3\"\n",
      "  type: RELU\n",
      "}\n",
      "layers {\n",
      "  bottom: \"conv3\"\n",
      "  top: \"pool3\"\n",
      "  name: \"pool3\"\n",
      "  type: POOLING\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layers {\n",
      "  bottom: \"pool3\"\n",
      "  top: \"ip1\"\n",
      "  name: \"ip1\"\n",
      "  type: INNER_PRODUCT\n",
      "  blobs_lr: 1\n",
      "  blobs_lr: 2\n",
      "  inner_product_param {\n",
      "    num_output: 64\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.1\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layers {\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip2\"\n",
      "  name: \"ip2\"\n",
      "  type: INNER_PRODUCT\n",
      "  blobs_lr: 1\n",
      "  blobs_lr: 2\n",
      "  inner_product_param {\n",
      "    num_output: 101\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.1\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layers {\n",
      "  bottom: \"ip2\"\n",
      "  top: \"loss\"\n",
      "  name: \"loss\"\n",
      "  type: SOFTMAX\n",
      "}\n",
      "I0305 10:53:55.449786 22019 net.cpp:67] Creating Layer allFrames_shuffled_sampled\n",
      "I0305 10:53:55.449815 22019 net.cpp:356] allFrames_shuffled_sampled -> data\n",
      "I0305 10:53:55.449852 22019 net.cpp:356] allFrames_shuffled_sampled -> label\n",
      "I0305 10:53:55.449874 22019 net.cpp:96] Setting up allFrames_shuffled_sampled\n",
      "I0305 10:53:55.450052 22019 data_layer.cpp:68] Opening lmdb ./test_lmdb_shuffle_sampled\n",
      "I0305 10:53:55.450258 22019 data_layer.cpp:128] output data size: 1,3,224,224\n",
      "I0305 10:53:55.450278 22019 base_data_layer.cpp:36] Loading mean file from./mean_shuffle_sampled.binaryproto\n",
      "I0305 10:53:55.452419 22019 net.cpp:103] Top shape: 1 3 224 224 (150528)\n",
      "I0305 10:53:55.452446 22019 net.cpp:103] Top shape: 1 1 1 1 (1)\n",
      "I0305 10:53:55.452471 22019 net.cpp:67] Creating Layer conv1\n",
      "I0305 10:53:55.452508 22019 net.cpp:394] conv1 <- data\n",
      "I0305 10:53:55.452533 22019 net.cpp:356] conv1 -> conv1\n",
      "I0305 10:53:55.452556 22019 net.cpp:96] Setting up conv1\n",
      "I0305 10:53:55.453346 22019 net.cpp:103] Top shape: 1 32 224 224 (1605632)\n",
      "I0305 10:53:55.453399 22019 net.cpp:67] Creating Layer pool1\n",
      "I0305 10:53:55.453415 22019 net.cpp:394] pool1 <- conv1\n",
      "I0305 10:53:55.453433 22019 net.cpp:356] pool1 -> pool1\n",
      "I0305 10:53:55.453450 22019 net.cpp:96] Setting up pool1\n",
      "I0305 10:53:55.453477 22019 net.cpp:103] Top shape: 1 32 112 112 (401408)\n",
      "I0305 10:53:55.453495 22019 net.cpp:67] Creating Layer relu1\n",
      "I0305 10:53:55.453508 22019 net.cpp:394] relu1 <- pool1\n",
      "I0305 10:53:55.453559 22019 net.cpp:345] relu1 -> pool1 (in-place)\n",
      "I0305 10:53:55.453577 22019 net.cpp:96] Setting up relu1\n",
      "I0305 10:53:55.453593 22019 net.cpp:103] Top shape: 1 32 112 112 (401408)\n",
      "I0305 10:53:55.453619 22019 net.cpp:67] Creating Layer conv2\n",
      "I0305 10:53:55.453634 22019 net.cpp:394] conv2 <- pool1\n",
      "I0305 10:53:55.453654 22019 net.cpp:356] conv2 -> conv2\n",
      "I0305 10:53:55.453671 22019 net.cpp:96] Setting up conv2\n",
      "I0305 10:53:55.455157 22019 net.cpp:103] Top shape: 1 32 112 112 (401408)\n",
      "I0305 10:53:55.455194 22019 net.cpp:67] Creating Layer relu2\n",
      "I0305 10:53:55.455209 22019 net.cpp:394] relu2 <- conv2\n",
      "I0305 10:53:55.455225 22019 net.cpp:345] relu2 -> conv2 (in-place)\n",
      "I0305 10:53:55.455241 22019 net.cpp:96] Setting up relu2\n",
      "I0305 10:53:55.455255 22019 net.cpp:103] Top shape: 1 32 112 112 (401408)\n",
      "I0305 10:53:55.455270 22019 net.cpp:67] Creating Layer pool2\n",
      "I0305 10:53:55.455282 22019 net.cpp:394] pool2 <- conv2\n",
      "I0305 10:53:55.455297 22019 net.cpp:356] pool2 -> pool2\n",
      "I0305 10:53:55.455314 22019 net.cpp:96] Setting up pool2\n",
      "I0305 10:53:55.455329 22019 net.cpp:103] Top shape: 1 32 56 56 (100352)\n",
      "I0305 10:53:55.455344 22019 net.cpp:67] Creating Layer conv3\n",
      "I0305 10:53:55.455358 22019 net.cpp:394] conv3 <- pool2\n",
      "I0305 10:53:55.455374 22019 net.cpp:356] conv3 -> conv3\n",
      "I0305 10:53:55.455391 22019 net.cpp:96] Setting up conv3\n",
      "I0305 10:53:55.458395 22019 net.cpp:103] Top shape: 1 64 56 56 (200704)\n",
      "I0305 10:53:55.458430 22019 net.cpp:67] Creating Layer relu3\n",
      "I0305 10:53:55.458443 22019 net.cpp:394] relu3 <- conv3\n",
      "I0305 10:53:55.458461 22019 net.cpp:345] relu3 -> conv3 (in-place)\n",
      "I0305 10:53:55.458477 22019 net.cpp:96] Setting up relu3\n",
      "I0305 10:53:55.458489 22019 net.cpp:103] Top shape: 1 64 56 56 (200704)\n",
      "I0305 10:53:55.458504 22019 net.cpp:67] Creating Layer pool3\n",
      "I0305 10:53:55.458518 22019 net.cpp:394] pool3 <- conv3\n",
      "I0305 10:53:55.458533 22019 net.cpp:356] pool3 -> pool3\n",
      "I0305 10:53:55.458549 22019 net.cpp:96] Setting up pool3\n",
      "I0305 10:53:55.458564 22019 net.cpp:103] Top shape: 1 64 28 28 (50176)\n",
      "I0305 10:53:55.458580 22019 net.cpp:67] Creating Layer ip1\n",
      "I0305 10:53:55.458592 22019 net.cpp:394] ip1 <- pool3\n",
      "I0305 10:53:55.458608 22019 net.cpp:356] ip1 -> ip1\n",
      "I0305 10:53:55.458626 22019 net.cpp:96] Setting up ip1\n",
      "I0305 10:53:55.649154 22019 net.cpp:103] Top shape: 1 64 1 1 (64)\n",
      "I0305 10:53:55.649221 22019 net.cpp:67] Creating Layer ip2\n",
      "I0305 10:53:55.649237 22019 net.cpp:394] ip2 <- ip1\n",
      "I0305 10:53:55.649258 22019 net.cpp:356] ip2 -> ip2\n",
      "I0305 10:53:55.649281 22019 net.cpp:96] Setting up ip2\n",
      "I0305 10:53:55.649688 22019 net.cpp:103] Top shape: 1 101 1 1 (101)\n",
      "I0305 10:53:55.649718 22019 net.cpp:67] Creating Layer loss\n",
      "I0305 10:53:55.649759 22019 net.cpp:394] loss <- ip2\n",
      "I0305 10:53:55.649775 22019 net.cpp:356] loss -> loss\n",
      "I0305 10:53:55.649793 22019 net.cpp:96] Setting up loss\n",
      "I0305 10:53:55.649813 22019 net.cpp:103] Top shape: 1 101 1 1 (101)\n",
      "I0305 10:53:55.649827 22019 net.cpp:172] loss does not need backward computation.\n",
      "I0305 10:53:55.649840 22019 net.cpp:172] ip2 does not need backward computation.\n",
      "I0305 10:53:55.649852 22019 net.cpp:172] ip1 does not need backward computation.\n",
      "I0305 10:53:55.649863 22019 net.cpp:172] pool3 does not need backward computation.\n",
      "I0305 10:53:55.649875 22019 net.cpp:172] relu3 does not need backward computation.\n",
      "I0305 10:53:55.649888 22019 net.cpp:172] conv3 does not need backward computation.\n",
      "I0305 10:53:55.649899 22019 net.cpp:172] pool2 does not need backward computation.\n",
      "I0305 10:53:55.649910 22019 net.cpp:172] relu2 does not need backward computation.\n",
      "I0305 10:53:55.649922 22019 net.cpp:172] conv2 does not need backward computation.\n",
      "I0305 10:53:55.649934 22019 net.cpp:172] relu1 does not need backward computation.\n",
      "I0305 10:53:55.649945 22019 net.cpp:172] pool1 does not need backward computation.\n",
      "I0305 10:53:55.649956 22019 net.cpp:172] conv1 does not need backward computation.\n",
      "I0305 10:53:55.649976 22019 net.cpp:172] allFrames_shuffled_sampled does not need backward computation.\n",
      "I0305 10:53:55.649988 22019 net.cpp:208] This network produces output label\n",
      "I0305 10:53:55.650035 22019 net.cpp:208] This network produces output loss\n",
      "I0305 10:53:55.650059 22019 net.cpp:467] Collecting Learning Rate and Weight Decay.\n",
      "I0305 10:53:55.650079 22019 net.cpp:219] Network initialization done.\n",
      "I0305 10:53:55.650092 22019 net.cpp:220] Memory required for data: 15655980\n",
      "I0305 10:53:55.689208 22019 caffe.cpp:145] Running for 1 iterations.\n",
      "I0305 10:53:55.780906 22019 caffe.cpp:169] Batch 0, label = 32\n",
      "I0305 10:53:55.783103 22019 caffe.cpp:169] Batch 0, loss = 0.010047\n",
      "I0305 10:53:55.783150 22019 caffe.cpp:169] Batch 0, loss = 0.00961618\n",
      "I0305 10:53:55.783196 22019 caffe.cpp:169] Batch 0, loss = 0.0102093\n",
      "I0305 10:53:55.783223 22019 caffe.cpp:169] Batch 0, loss = 0.0100273\n",
      "I0305 10:53:55.783251 22019 caffe.cpp:169] Batch 0, loss = 0.00961008\n",
      "I0305 10:53:55.783277 22019 caffe.cpp:169] Batch 0, loss = 0.0103932\n",
      "I0305 10:53:55.783301 22019 caffe.cpp:169] Batch 0, loss = 0.0101413\n",
      "I0305 10:53:55.783327 22019 caffe.cpp:169] Batch 0, loss = 0.00993649\n",
      "I0305 10:53:55.783354 22019 caffe.cpp:169] Batch 0, loss = 0.0101155\n",
      "I0305 10:53:55.783380 22019 caffe.cpp:169] Batch 0, loss = 0.0103679\n",
      "I0305 10:53:55.783404 22019 caffe.cpp:169] Batch 0, loss = 0.0101035\n",
      "I0305 10:53:55.783431 22019 caffe.cpp:169] Batch 0, loss = 0.0100854\n",
      "I0305 10:53:55.783455 22019 caffe.cpp:169] Batch 0, loss = 0.00983509\n",
      "I0305 10:53:55.783483 22019 caffe.cpp:169] Batch 0, loss = 0.00963998\n",
      "I0305 10:53:55.783507 22019 caffe.cpp:169] Batch 0, loss = 0.00958064\n",
      "I0305 10:53:55.783535 22019 caffe.cpp:169] Batch 0, loss = 0.0105444\n",
      "I0305 10:53:55.783560 22019 caffe.cpp:169] Batch 0, loss = 0.0104419\n",
      "I0305 10:53:55.783586 22019 caffe.cpp:169] Batch 0, loss = 0.0099154\n",
      "I0305 10:53:55.783612 22019 caffe.cpp:169] Batch 0, loss = 0.0092118\n",
      "I0305 10:53:55.783637 22019 caffe.cpp:169] Batch 0, loss = 0.0097413\n",
      "I0305 10:53:55.783661 22019 caffe.cpp:169] Batch 0, loss = 0.00971739\n",
      "I0305 10:53:55.783687 22019 caffe.cpp:169] Batch 0, loss = 0.00974267\n",
      "I0305 10:53:55.783718 22019 caffe.cpp:169] Batch 0, loss = 0.0102133\n",
      "I0305 10:53:55.783746 22019 caffe.cpp:169] Batch 0, loss = 0.010542\n",
      "I0305 10:53:55.783771 22019 caffe.cpp:169] Batch 0, loss = 0.00953141\n",
      "I0305 10:53:55.783795 22019 caffe.cpp:169] Batch 0, loss = 0.0104378\n",
      "I0305 10:53:55.783820 22019 caffe.cpp:169] Batch 0, loss = 0.0107075\n",
      "I0305 10:53:55.783845 22019 caffe.cpp:169] Batch 0, loss = 0.00941875\n",
      "I0305 10:53:55.783870 22019 caffe.cpp:169] Batch 0, loss = 0.00978815\n",
      "I0305 10:53:55.783903 22019 caffe.cpp:169] Batch 0, loss = 0.00974486\n",
      "I0305 10:53:55.783929 22019 caffe.cpp:169] Batch 0, loss = 0.00985153\n",
      "I0305 10:53:55.783956 22019 caffe.cpp:169] Batch 0, loss = 0.00998786\n",
      "I0305 10:53:55.783982 22019 caffe.cpp:169] Batch 0, loss = 0.00998568\n",
      "I0305 10:53:55.784008 22019 caffe.cpp:169] Batch 0, loss = 0.00994011\n",
      "I0305 10:53:55.784034 22019 caffe.cpp:169] Batch 0, loss = 0.00997482\n",
      "I0305 10:53:55.784059 22019 caffe.cpp:169] Batch 0, loss = 0.0102614\n",
      "I0305 10:53:55.784083 22019 caffe.cpp:169] Batch 0, loss = 0.00970271\n",
      "I0305 10:53:55.784109 22019 caffe.cpp:169] Batch 0, loss = 0.00941912\n",
      "I0305 10:53:55.784134 22019 caffe.cpp:169] Batch 0, loss = 0.0104025\n",
      "I0305 10:53:55.784160 22019 caffe.cpp:169] Batch 0, loss = 0.00983478\n",
      "I0305 10:53:55.784185 22019 caffe.cpp:169] Batch 0, loss = 0.00967896\n",
      "I0305 10:53:55.784211 22019 caffe.cpp:169] Batch 0, loss = 0.0106589\n",
      "I0305 10:53:55.784236 22019 caffe.cpp:169] Batch 0, loss = 0.00977467\n",
      "I0305 10:53:55.784262 22019 caffe.cpp:169] Batch 0, loss = 0.0105188\n",
      "I0305 10:53:55.784291 22019 caffe.cpp:169] Batch 0, loss = 0.00978854\n",
      "I0305 10:53:55.784327 22019 caffe.cpp:169] Batch 0, loss = 0.00958116\n",
      "I0305 10:53:55.784354 22019 caffe.cpp:169] Batch 0, loss = 0.00990993\n",
      "I0305 10:53:55.784381 22019 caffe.cpp:169] Batch 0, loss = 0.00996057\n",
      "I0305 10:53:55.784406 22019 caffe.cpp:169] Batch 0, loss = 0.00999409\n",
      "I0305 10:53:55.784431 22019 caffe.cpp:169] Batch 0, loss = 0.00957556\n",
      "I0305 10:53:55.784457 22019 caffe.cpp:169] Batch 0, loss = 0.0097228\n",
      "I0305 10:53:55.784482 22019 caffe.cpp:169] Batch 0, loss = 0.00989254\n",
      "I0305 10:53:55.784508 22019 caffe.cpp:169] Batch 0, loss = 0.00959422\n",
      "I0305 10:53:55.784548 22019 caffe.cpp:169] Batch 0, loss = 0.0100274\n",
      "I0305 10:53:55.784581 22019 caffe.cpp:169] Batch 0, loss = 0.00942379\n",
      "I0305 10:53:55.784608 22019 caffe.cpp:169] Batch 0, loss = 0.0101495\n",
      "I0305 10:53:55.784633 22019 caffe.cpp:169] Batch 0, loss = 0.00935208\n",
      "I0305 10:53:55.784659 22019 caffe.cpp:169] Batch 0, loss = 0.00959651\n",
      "I0305 10:53:55.784684 22019 caffe.cpp:169] Batch 0, loss = 0.0106419\n",
      "I0305 10:53:55.784709 22019 caffe.cpp:169] Batch 0, loss = 0.0103855\n",
      "I0305 10:53:55.784734 22019 caffe.cpp:169] Batch 0, loss = 0.0104327\n",
      "I0305 10:53:55.784759 22019 caffe.cpp:169] Batch 0, loss = 0.0105444\n",
      "I0305 10:53:55.784783 22019 caffe.cpp:169] Batch 0, loss = 0.010545\n",
      "I0305 10:53:55.784811 22019 caffe.cpp:169] Batch 0, loss = 0.00918817\n",
      "I0305 10:53:55.784837 22019 caffe.cpp:169] Batch 0, loss = 0.0102999\n",
      "I0305 10:53:55.784862 22019 caffe.cpp:169] Batch 0, loss = 0.00955119\n",
      "I0305 10:53:55.784886 22019 caffe.cpp:169] Batch 0, loss = 0.0093046\n",
      "I0305 10:53:55.784911 22019 caffe.cpp:169] Batch 0, loss = 0.010172\n",
      "I0305 10:53:55.784936 22019 caffe.cpp:169] Batch 0, loss = 0.00935569\n",
      "I0305 10:53:55.784961 22019 caffe.cpp:169] Batch 0, loss = 0.00913978\n",
      "I0305 10:53:55.784986 22019 caffe.cpp:169] Batch 0, loss = 0.0102677\n",
      "I0305 10:53:55.785011 22019 caffe.cpp:169] Batch 0, loss = 0.00919225\n",
      "I0305 10:53:55.785035 22019 caffe.cpp:169] Batch 0, loss = 0.0093193\n",
      "I0305 10:53:55.785060 22019 caffe.cpp:169] Batch 0, loss = 0.0100226\n",
      "I0305 10:53:55.785085 22019 caffe.cpp:169] Batch 0, loss = 0.00941641\n",
      "I0305 10:53:55.785111 22019 caffe.cpp:169] Batch 0, loss = 0.00993558\n",
      "I0305 10:53:55.785136 22019 caffe.cpp:169] Batch 0, loss = 0.00977336\n",
      "I0305 10:53:55.785161 22019 caffe.cpp:169] Batch 0, loss = 0.0105238\n",
      "I0305 10:53:55.785187 22019 caffe.cpp:169] Batch 0, loss = 0.0103626\n",
      "I0305 10:53:55.785212 22019 caffe.cpp:169] Batch 0, loss = 0.00954763\n",
      "I0305 10:53:55.785236 22019 caffe.cpp:169] Batch 0, loss = 0.00982931\n",
      "I0305 10:53:55.785261 22019 caffe.cpp:169] Batch 0, loss = 0.00923184\n",
      "I0305 10:53:55.785286 22019 caffe.cpp:169] Batch 0, loss = 0.00968352\n",
      "I0305 10:53:55.785312 22019 caffe.cpp:169] Batch 0, loss = 0.0101713\n",
      "I0305 10:53:55.785336 22019 caffe.cpp:169] Batch 0, loss = 0.010058\n",
      "I0305 10:53:55.785362 22019 caffe.cpp:169] Batch 0, loss = 0.00929719\n",
      "I0305 10:53:55.785390 22019 caffe.cpp:169] Batch 0, loss = 0.00950997\n",
      "I0305 10:53:55.785416 22019 caffe.cpp:169] Batch 0, loss = 0.00986729\n",
      "I0305 10:53:55.785442 22019 caffe.cpp:169] Batch 0, loss = 0.00997283\n",
      "I0305 10:53:55.785467 22019 caffe.cpp:169] Batch 0, loss = 0.0100032\n",
      "I0305 10:53:55.785492 22019 caffe.cpp:169] Batch 0, loss = 0.00926699\n",
      "I0305 10:53:55.785517 22019 caffe.cpp:169] Batch 0, loss = 0.0106061\n",
      "I0305 10:53:55.785542 22019 caffe.cpp:169] Batch 0, loss = 0.00980864\n",
      "I0305 10:53:55.785567 22019 caffe.cpp:169] Batch 0, loss = 0.00991424\n",
      "I0305 10:53:55.785595 22019 caffe.cpp:169] Batch 0, loss = 0.00998448\n",
      "I0305 10:53:55.785621 22019 caffe.cpp:169] Batch 0, loss = 0.00931214\n",
      "I0305 10:53:55.785646 22019 caffe.cpp:169] Batch 0, loss = 0.00945166\n",
      "I0305 10:53:55.785671 22019 caffe.cpp:169] Batch 0, loss = 0.00968032\n",
      "I0305 10:53:55.785696 22019 caffe.cpp:169] Batch 0, loss = 0.0101471\n",
      "I0305 10:53:55.785722 22019 caffe.cpp:169] Batch 0, loss = 0.0103083\n",
      "I0305 10:53:55.785747 22019 caffe.cpp:169] Batch 0, loss = 0.0100056\n",
      "I0305 10:53:55.785774 22019 caffe.cpp:175] Loss: 0\n",
      "I0305 10:53:55.785790 22019 caffe.cpp:187] label = 32\n",
      "I0305 10:53:55.785805 22019 caffe.cpp:187] loss = 0.010047\n",
      "Segmentation fault (core dumped)\n"
     ]
    }
   ],
   "source": [
    "/afs/cs.stanford.edu/u/anenberg/scr/CS231N/examples/allFrames/test_quick.sh > tmp.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "more tmp.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/afs/cs.stanford.edu/u/anenberg/scr/CS231N/examples/allFrames\n"
     ]
    }
   ],
   "source": [
    "cd /afs/cs.stanford.edu/u/anenberg/scr/CS231N/examples/allFrames/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
